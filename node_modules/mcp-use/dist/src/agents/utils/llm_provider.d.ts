import type { LanguageModel } from "../types.js";
/**
 * Configuration for LLM instances
 */
export interface LLMConfig {
    apiKey?: string;
    temperature?: number;
    maxTokens?: number;
    topP?: number;
    [key: string]: any;
}
/**
 * Supported LLM providers
 */
export type LLMProvider = "openai" | "anthropic" | "google" | "groq";
/**
 * Parse LLM string format: "provider/model"
 * Examples:
 *   - "openai/gpt-4" -> { provider: "openai", model: "gpt-4" }
 *   - "anthropic/claude-3-5-sonnet-20241022" -> { provider: "anthropic", model: "claude-3-5-sonnet-20241022" }
 *   - "google/gemini-pro" -> { provider: "google", model: "gemini-pro" }
 */
export declare function parseLLMString(llmString: string): {
    provider: LLMProvider;
    model: string;
};
/**
 * Dynamically import and instantiate an LLM from a string specification
 *
 * @param llmString - LLM specification in format "provider/model" (e.g., "openai/gpt-4")
 * @param config - Optional configuration for the LLM (apiKey, temperature, etc.)
 * @returns Promise<LanguageModel> - Instantiated LLM instance
 *
 * @example
 * ```typescript
 * const llm = await createLLMFromString('openai/gpt-4', { temperature: 0.7 });
 * ```
 *
 * @example
 * ```typescript
 * const llm = await createLLMFromString('anthropic/claude-3-5-sonnet-20241022');
 * ```
 */
export declare function createLLMFromString(llmString: string, config?: LLMConfig): Promise<LanguageModel>;
/**
 * Validate that an LLM string is in the correct format
 */
export declare function isValidLLMString(llmString: string): boolean;
/**
 * Get list of supported providers
 */
export declare function getSupportedProviders(): LLMProvider[];
//# sourceMappingURL=llm_provider.d.ts.map